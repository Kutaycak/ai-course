{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Big Data Machine Learning Classification with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Churn Prediction\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "data = spark.read.csv(\"churn_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Define features and target variable\n",
    "feature_columns = ['feature1', 'feature2', 'feature3']  # Add your features here\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
    "\n",
    "# Create features\n",
    "data = assembler.transform(data)\n",
    "\n",
    "# Separate target variable\n",
    "final_data = data.select('features', 'label')  # Your target variable is 'label'\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Create GBTClassifier model\n",
    "gbt = GBTClassifier(labelCol='label', featuresCol='features', maxIter=10)\n",
    "\n",
    "# Train the model with training data\n",
    "model = gbt.fit(train_data)\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Display prediction results\n",
    "predictions.select('features', 'label', 'prediction').show(5)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
